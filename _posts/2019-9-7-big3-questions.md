---
title:  "The Big Three: A Methodology to Increase Data Science ROI by Answering the Questions Companies Care About."
last_modified_at: 2019-09-06T16:00:58-04:00

header:
    overlay_image: /assets/images/unsplash-image-1.jpg
    overlay_filter: 0.5 # same as adding an opacity of 0.5 to a black background
  
toc: true
toc_label: "The Big Three: A Methodology to Increase Data Science ROI by Answering the Questions Companies Care About."

---

<!--Comment to remove bug showing full post-->

## Data Science Applied In Business Today.

In the past decade, there has been an explosion in the application of data science outside of academic realms. The use of general, statistical, predictive machine learning models has achieved high success rates across multiple occupations including finance, marketing, sales, and engineering, as well as multiple industries including entertainment, online and store front retail, transportation, service and hospitality, healthcare, insurance, manufacturing and many others. The applications of data science seem to be nearly endless in today's modern landscape, with each company jockeying for position in the new data and insights economy. Yet, what if I told you that companies may be achieving only a third of the value they could be getting with the use of data science for their companies? I know, it sounds almost fantastical given how much success has already been achieved using data science. However, many opportunities for value generation may be getting over looked because data scientists and statisticians are not traditionally trained to answer some of the questions companies in industry care about. 

Most of the technical data science analysis done today is either classification (labeling with discrete values), regression (labeling with a number), or pattern recognition. These forms of analysis answer the business questions 'can I understand what is going on' and 'can I predict what will happen next'. Examples of questions are 'can I predict which customers will churn?', 'can I forecast my next quarter revenue?', 'can I predict products customers are interested in?', 'are there important customer activity patterns?', etc... These are extremely valuable questions to companies that can be answered by data science. In fact, answering these questions is what has caused the explosion in interest in applying data science in business applications. However, most companies have two other major categories of important questions that are being totally ignored. Namely, once a problem has been identified or predicted, can we determine what's causing it? Furthermore, can we take action to resolve or prevent the problem?

We start this article discussing why most data driven companies aren't as data driven as they think they are. We then introduce the idea of the 3 categories of questions companies care about the most (The Big 3), discuss why data scientists have been missing these opportunities. We then outline how data scientists and companies can partner to answer these questions.

## Why Even Advaned Tech Companies Aren't as Data Driven As They Think They Are.

Many companies want to become more 'data driven', and to generate more 'prescriptive insights'. They want to use data to make effective decisions about their business plans, operations, products and services. The current idea of being 'data driven' and 'prescriptive insights' in the industry today seems to be defined as using trends or descriptive statistics about about data to try to make informed business decisions. This is the most basic form of being data driven. Some companies, particularly the more advanced technology companies go a step further and use predictive machine learning models and more advanced statistical inference and analysis methods to generate more advanced descriptive numbers. But that's just it. These numbers, even those generated by predictive machine learning models, are just descriptive. They may be descriptive in different ways, such as machine learning generating a descriptive number about something that may happen in the future while a desrtiptive statistic indicates what is happening in the present, but there is nothing inherintly 'prescriptive' about these numbers. Why is that? 

Take the example diagram shown in figure 1 below. Figure 1 shows a very common business problem of predicting the risk of a customer churning. For this problem, a data scientist may gather many pieces of data (features) about a customer and then build a predictive model. Once a model is developed, it is deployed as a continually running insight service, and integrated into a business process. In this case, let's say we have a renewal manager that wants to use these insights. The business process is as follows. First, the automated insight service that was deployed gathers data about the customer. It then passes that data to the predictive model. The predictive model then outputs a predicted risk of churn number. This number is then passed to the renewal manager. The renewal manager then uses their gut intuition to determine what action to take to reduce the risk of churn. This all seems straightforward enough. However, we've broken the chain of being data driven. How is that you ask? Well, our data driven business process stopped at the point of generating our churn risk number. We simply gave our churn risk number to a human, and they used their gut intuition to make a decision. This isn't data driven decision making, this is gut driven decision making. It's a subtle thing to notice, so don't feel too bad if you didn't see it at first. In fact, most people don't recognize this subtelty. That's because it's so natural these days to think that getting a number to a human is how making 'data driven decisions' works. The subtelty exists because we are not using data and statistical methods to evaluate the impact of actions the human can take on the metric they care about. A human sees a number or a graph, and then *decides* to take *action*. This implies they have an idea about how their *action* will *effect* the number or graph that they see. Thus, they are making a cause and effect judgement about their decision making and their actions. Yet, they aren't using any sort of mathematical methods of evaluating their options. They are simply using their personal judgement to make a decision. What can end up happening in this case is that a human may see a number, make a decision, and end up making that number worse. 

Let's take the churn risk example again. Let's say the customer is 70% likely to churn and that they were likely to churn because their experience with the service was poor, but assume that the renewal manager doesn't know this (this too is actually a cause and effect statement). Let's say that a renewal manager sends a specially crafted renewal email to this customer in an attempt to reduce the likelihood of churn. That seems like a reasonable action to take, right? However, this customer recieves the email, and is reminded of how bad their experience was, and now even more annoyed with our company. Suddenly the likelihood to churn increases to 90% for this customer. If we had taken no action, or possibly a different action (say connecting them with digital support resources) then we would have been better off. But without an analysis of cause and effect, and without systems that can analyze our actions and prescribe the best ones to take, we are gambling with the metrics we care about.

**Figure 1**
!['Prescriptive Insights' Fallacy](/assets/images/posts/big3_without_pae.png)

So how can we attempt to solve this problem? We need to incorporate mathematical models and measurement into the business process after the number is generated. We need to collect data on what actions are being taken, measure their relationship with the metrics we care about, and then optimize over our actions using AI systems. Figure 2 below shows how we can insert an AI system into the business process to help track, measure, and optimize the actions our company is taking. Using a combination of mathematical analysis methods, we can begin to optimize the entire process using data science end to end. The stages of this process can be abstracted and generalized as answering 3 categories of questions companys care about. Those 3 categories are described in the next section.

**Figure 2**
![Intelligent Actions](/assets/images/posts/big3_with_pae.png)

## What Are the Big 3?

**Figure 3**
![The Big 3](/assets/images/posts/big3_text_description.png)

Figure 3 above describes what 'The Big 3' questions companies care about are. The big 3 questions seem fairly obvious. In fact, these questions are at the foundation of most of problem solving in the real world. Yet, almost all data science in industry today revolves around answering only the first question. What most data scientists understand as supervised, unsupervised, and semi-supervised learning revolves around answering what is happening or what will happen. Even with something like product recommendation system (which you might believe prescribes something because of the term 'recommend'), we only know what products a customer is interested in (thus it is does not give prescribed actions). We don't know the most effective way to act on that information. Should we send an ad? Should we call them? Do certain engagements with them cause a decrease their chances of purchase? To answer what is *causing* something to happen, we need to rely on controlled testing and the foundational work in the area of Causal Inference developed by researchers and statisticians like Judea Pearl. Once we understand what is causing a metric we can care about, we can at least begin to think intelligently about the actions we can take to change those metrics. This is where the third question mentioned in figure 3 above comes in. To answer this question we can rely on a wide variety of techniques that have been developed including causal inference for the cause and effect relationship between actions and the metrics they are supposed to affect, statistical decision theory, decision support systems, control systems, and reinforcement learning. 

## Why Many Data Scientists Don't Know the Big 3, or How to Answer Them.

Those learned readers experienced with data science may be asking themselves, 'is anything new being said here'? It's true that I'm not really proposing a new technical algorithm here. I'm not presenting some new mathematical modeling method, or some novel comparison of existing methods. What is new is how I'm framing the problems for data science in industry and the existing methodologies that can start to solve those problems. Causal inference has been used heavily in medicine for observational studies where controlled trials aren't feasible, and for things like adverse drug effect discovery. However, Causal Inference hasn't recieved wide spread application in areas outside of the medical field yet. The idea of prescribed actions is also something that isn't totally new. Prescribed actions can be thought of as just a restatement of the field of control systems, decision analysis, and intelligent agent theory. However, the utilization of these methods for completing the end-to-end data driven methodology for business hasn't recieved wide spread application in industry applications either. Why is this? Why aren't data scientists and businesses working together to frame all of their problems this way?

There could be a couple of reasons for this. The most obvious answer is that most data scientists are trained to answer the first of the big 3 questions. Most data scientists and statisticians are trained on statistical inference, classification, regression, and general unsupervised learning methods like clustering and anomaly detection. Statistical methods like causal inference aren't widely known, and are therefore not widely taught. Register with any online course, university, or other platform for learning about data science and machine learning and you'll be hard pressed to find discussions about identifying causal patterns in data sets. The same goes for the ideas of intelligent agents, control systems, and reinforcement learning to a lesser degree. These methods tend to be relegated to domains that have simulators and a tolerance for failure. Thankfully there is less of a gap for these methods. They typically are given their own special courses in either machine learning, electronics, and signals and systems processing curriculums. 

Another possible explanation may be that many data scientists in industry tend to be enamoured with the latest and greatest popular algorithm or methodology. As math and tech nerds we become enamoured with the technical intricacies of how things work, particularly mathematical algorithms and methodologies. We can sometimes tend to develop models and then go looking for solutions rather than the other way around, potentially blinding us to the natural generalizations lying in the questions companies ask time and time again.

Yet another explanation may be that many data scientists are not well versed enough in statistics and the statistical literature. Many data scientists are asked questions about how a predictive model produced a number. For example, in our churn risk problem, renewal managers typically want to know why someone is at risk. The average data scientist hears this, and then uses methods like feature importance and more interpretable models to answer this question. However this doesn't really answer the actual question being asked. The data scientist provides what might be important associations between model inputs and the predicted metric, but this doesn't provide the information the renewal manager wants. They want to know about information they can act on, which requires cause and effect analysis. This is a classic case of 'correlation is not causation' that everyone seems to know but can still trip up even statistically minded data scientists. It's such an issue that many companies I've talked with that claim to provide 'next best actions' are statistically invalid (mainly because they use feature importance and sensitivity analysis type methods instead of understanding basic counter factual analysis and confounding variables).

Moving forward the data science community operating in industry domains will become more aware of the big 3 questions and the analysis methods that can be performed to answer them. Companies that can quickly realize value from answering these questions using data science will be far ahead of most companies in most industries. Companies that focus on answering all of the big 3 questions will have a distinct competitive advantage, and will have transformed themselves to be truly data driven.

## Conclusions

Every company wants to get the most out of their data science initiatives. In this article, we introduced how to get more value by decomposing business problems into one of 'The Big 3' questions. So many companies are missing out on valueable opportunities for data science to add value to their business strategy. Even large companies that consider themselves to be 'data driven' typically ignore the added value they could gain by answering all of 'The Big 3' questions. In this article I've mentioned what 'The Big 3' are, and technical data science methodologies that can be used to answer these questions. I've also outlined why many data scientists may not know about these questions and methods, may not be applying them, or may even be incorrectly applying methods in an attempt to answer these questions. In the last section I discussed how we in the Customer Experience organization are applying these advanced methods to strategically optimize our customer experiences. Companies that decide to frame their problems in terms of 'The Big 3' will have a very important competitive advantage in their journey to becoming data driven. By answering the entire, end-to-end set of questions that businesses care about, companies can be mathematically strategic in how they apply data science to understand their data, and to make decisions using that data.

## Further Information

In this post, I've outlined most of the concepts of 'the big 3' questions, and some technical information. I have also written a much deeper technical paper outlining the method I've proposed ('The Big 3') for categorizing business questions and approaching a full end-to-end data driven value realization strategy for maximizing ROI from data science in industrial applications. The paper also surveys a variety of methods to answer each of the big 3 questions, as well as applications of these methods to various domains. The full technical paper can be found [here](/papers/The_Big_Three__Using_Data_Science_to_Get_Value_in_Industry.pdf).




































